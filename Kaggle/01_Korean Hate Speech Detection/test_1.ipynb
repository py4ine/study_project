{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/tfGPU/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/tfGPU/lib/python3.9/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score, roc_auc_score\n",
    "\n",
    "# from pykospacing import Spacing\n",
    "# import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r'./data/korean-hate-speech-detection/train.hate.csv')\n",
    "\n",
    "train_text = open(r'./data/korean-hate-speech-detection/train.news_title.txt', 'r')\n",
    "train_texts = train_text.readlines()\n",
    "\n",
    "train_text_list = []\n",
    "for line in train_texts:\n",
    "    train_text_list.append(line)\n",
    "train_text.close()\n",
    "\n",
    "train_df['text'] = train_text_list\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengh = []\n",
    "for i in train_df['comments']:\n",
    "    lengh.append(len(i))\n",
    "max(lengh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing = Spacing()\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = spacing(text)\n",
    "    text = text.lower()  # 소문자 변경\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# 기본 불용어 불러오기\n",
    "korean_stopwords_path = \"data/stopwords-ko.txt\"\n",
    "with open(korean_stopwords_path, encoding='utf8') as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [x.strip() for x in stopwords]\n",
    "\n",
    "# 불용어 처리 함수 수정\n",
    "def remove_stopwords(text, stopwords):\n",
    "    words = text.split()  # 문장을 단어로 분리\n",
    "    filtered_text = [word for word in words if word not in stopwords]  # 단어가 불용어 목록에 없는 경우만 추가\n",
    "    return ' '.join(filtered_text)  # 필터링된 단어들 다시 조합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 전처리 및 불용어 처리\n",
    "for i in tqdm(range(len(train_df))):\n",
    "    comment_text = train_df.loc[i, 'comments']\n",
    "    newstile_text = train_df.loc[i, 'text']\n",
    "    processed_comment = preprocessing(comment_text)\n",
    "    processed_newstile = preprocessing(newstile_text)\n",
    "    cleaned_comment = remove_stopwords(processed_comment, stopwords)\n",
    "    cleaned_newstile = remove_stopwords(processed_newstile, stopwords)\n",
    "    train_df.loc[i, 'processed_comments'] = cleaned_comment\n",
    "    train_df.loc[i, 'processed_newstitle'] = cleaned_newstile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['label'] == 'none', 'labels'] = 0\n",
    "train_df.loc[train_df['label'] == 'offensive', 'labels'] = 1\n",
    "train_df.loc[train_df['label'] == 'hate', 'labels'] = 2\n",
    "\n",
    "train_df['labels'] = train_df['labels'].astype(int)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('./data/train_df_processed.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = pd.read_csv(r'./data/korean-hate-speech-detection/dev.hate.csv')\n",
    "\n",
    "dev_text = open(r'./data/korean-hate-speech-detection/dev.news_title.txt', 'r')\n",
    "dev_texts = dev_text.readlines()\n",
    "\n",
    "dev_text_list = []\n",
    "for line in dev_texts:\n",
    "    dev_text_list.append(line)\n",
    "dev_text.close\n",
    "\n",
    "dev_df['text'] = dev_text_list\n",
    "dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 전처리 및 불용어 처리\n",
    "for i in tqdm(range(len(dev_df))):\n",
    "    comment_text = dev_df.loc[i, 'comments']\n",
    "    newstile_text = dev_df.loc[i, 'text']\n",
    "    processed_comment = preprocessing(comment_text)\n",
    "    processed_newstile = preprocessing(newstile_text)\n",
    "    cleaned_comment = remove_stopwords(processed_comment, stopwords)\n",
    "    cleaned_newstile = remove_stopwords(processed_newstile, stopwords)\n",
    "    dev_df.loc[i, 'processed_comments'] = cleaned_comment\n",
    "    dev_df.loc[i, 'processed_newstitle'] = cleaned_newstile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.loc[dev_df['label'] == 'none', 'labels'] = 0\n",
    "dev_df.loc[dev_df['label'] == 'offensive', 'labels'] = 1\n",
    "dev_df.loc[dev_df['label'] == 'hate', 'labels'] = 2\n",
    "dev_df['labels'] = dev_df['labels'].astype(int)\n",
    "\n",
    "dev_df.to_csv('./data/dev_df_processed.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = pd.read_csv('./data/dev_df_processed.csv')\n",
    "dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(r'./data/korean-hate-speech-detection/test.hate.no_label.csv')\n",
    "\n",
    "test_text = open(r'./data/korean-hate-speech-detection/test.news_title.txt')\n",
    "test_texts = test_text.readlines()\n",
    "test_text_list = []\n",
    "for line in test_texts:\n",
    "    test_text_list.append(line)\n",
    "\n",
    "test_df['text'] = test_text_list\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 전처리 및 불용어 처리\n",
    "for i in tqdm(range(len(test_df))):\n",
    "    comment_text = test_df.loc[i, 'comments']\n",
    "    newstile_text = test_df.loc[i, 'text']\n",
    "    processed_comment = preprocessing(comment_text)\n",
    "    processed_newstile = preprocessing(newstile_text)\n",
    "    cleaned_comment = remove_stopwords(processed_comment, stopwords)\n",
    "    cleaned_newstile = remove_stopwords(processed_newstile, stopwords)\n",
    "    test_df.loc[i, 'processed_comments'] = cleaned_comment\n",
    "    test_df.loc[i, 'processed_newstitle'] = cleaned_newstile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('./data/test_df_processed.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r'./data/train_df_processed.csv')\n",
    "dev_df = pd.read_csv(r'./data/dev_df_processed.csv')\n",
    "test_df = pd.read_csv(r'./data/test_df_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/tfGPU/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/tfGPU/lib/python3.9/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/tfGPU/lib/python3.9/site-packages/transformers/modeling_utils.py:484: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'beomi/KcELECTRA-base-v2022'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(54343, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPU 설정\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# print(\"device:\", device)\n",
    "\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(\"device:\", device)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터 토크나이징\n",
    "\n",
    "# tokenized_train = tokenizer(\n",
    "#     list(train_df['processed_comments']),\n",
    "#     return_tensors='pt',\n",
    "#     max_length=128,\n",
    "#     padding=True,\n",
    "#     truncation=True,          # max_length 초과 토큰 truncate\n",
    "#     add_special_tokens=True,  # special token 추가\n",
    "# )\n",
    "\n",
    "# tokenized_dev = tokenizer(\n",
    "#     list(dev_df['processed_comments']),\n",
    "#     return_tensors='pt',\n",
    "#     max_length=128,\n",
    "#     padding=True,\n",
    "#     truncation=True,          # max_length 초과 토큰 truncate\n",
    "#     add_special_tokens=True,  # special token 추가\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터 셋 설정\n",
    "# class CurseDataSet(torch.utils.data.Dataset):\n",
    "#     def __init__(self, encodings, labels):\n",
    "#         self.encodings = encodings\n",
    "#         self.labels = labels\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "#         item['labels'] = torch.tensor(self.labels[idx])\n",
    "#         return item\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.labels)\n",
    "    \n",
    "# train_label = train_df['labels'].values\n",
    "# dev_label = dev_df['labels'].values\n",
    "\n",
    "# train_dataset = CurseDataSet(tokenized_train, train_label)\n",
    "# dev_dataset = CurseDataSet(tokenized_dev, dev_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KF_DeBERT모델 텍스트 토큰화\n",
    "train_encodings = tokenizer(train_df['processed_comments'].tolist(), truncation=True, padding=True)  # truncation=최대길이를 초과하는 것에 대한 처리\n",
    "train_df['encoding'] = train_encodings\n",
    "dev_encodings = tokenizer(dev_df['processed_comments'].tolist(), truncation=True, padding=True)  # truncation=최대길이를 초과하는 것에 대한 처리\n",
    "dev_df['encoding'] = dev_encodings\n",
    "\n",
    "# 데이터셋 준비\n",
    "train_df['input_ids'] = train_encodings['input_ids']  # input_ids=문장을 토크나이저가 일정 단위로 쪼개서 vocab에 들어있는 숫자로 치환한 것\n",
    "train_df['attention_mask'] = train_encodings['attention_mask']  # attention_mask=attention대상인지 아닌지를 나타냄. 대상이면1, 아니면0, 패딩된건 0으로 학습대상x\n",
    "dev_df['input_ids'] = dev_encodings['input_ids']  # input_ids=문장을 토크나이저가 일정 단위로 쪼개서 vocab에 들어있는 숫자로 치환한 것\n",
    "dev_df['attention_mask'] = dev_encodings['attention_mask']  # attention_mask=attention대상인지 아닌지를 나타냄. 대상이면1, 아니면0, 패딩된건 0으로 학습대상x\n",
    "\n",
    "X_train = train_df[['input_ids', 'attention_mask']]\n",
    "y_train = train_df['labels']\n",
    "X_test = dev_df[['input_ids', 'attention_mask']]\n",
    "y_test = dev_df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(X_train.join(y_train))\n",
    "dev_dataset = Dataset.from_pandas(X_test.join(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 하이퍼파라미터 옵션 설정\n",
    "param_grid = {\n",
    "    'learning_rate': [5e-5],  # 2e-5, 3e-5, 5e-5\n",
    "    'per_device_train_batch_size': [8],\n",
    "    'num_train_epochs': [3]\n",
    "}\n",
    "\n",
    "# param_grid = {\n",
    "#     'learning_rate': [3e-5, 2e-5, 5e-5],  # 학습률\n",
    "#     'per_device_train_batch_size': [4, 8, 16, 32],  # 베치크기\n",
    "#     'num_train_epochs': [2, 4, 6, 8]  # 에포크 수\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 76.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with parameters: learning_rate=5e-05, batch_size=8, epochs=3\n",
      "Exception: __init__() got an unexpected keyword argument 'dispatch_batches'\n",
      "Best Parameters: None\n",
      "Best Accuracy: 0\n",
      "Best F1: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# 수치 초기화\n",
    "best_accuracy = 0\n",
    "best_F1 = 0\n",
    "best_params = None\n",
    "results = []\n",
    "\n",
    "for learning_rate in tqdm(param_grid['learning_rate']):\n",
    "    for batch_size in param_grid['per_device_train_batch_size']:\n",
    "        for epochs in param_grid['num_train_epochs']:\n",
    "            try:\n",
    "                if batch_size > len(train_dataset):\n",
    "                    print(f\"Skipping batch size {batch_size} as it is larger than the dataset size {len(train_dataset)}\")\n",
    "                    continue\n",
    "\n",
    "                # TrainingArguments 설정\n",
    "                training_args = TrainingArguments(\n",
    "                    output_dir=\"./results\",  # 학습된 모델과 결과를 저장할 경로 설정\n",
    "                    run_name=\"my_experiment\",  # 고유한 run_name 설정  // 로그인 피하기위해\n",
    "                    evaluation_strategy=\"epoch\",  # 각 에포크마다 평가 수행\n",
    "                    learning_rate=learning_rate,  # 학습률 설정\n",
    "                    per_device_train_batch_size=batch_size,  # 학습 배치 크기 설정\n",
    "                    per_device_eval_batch_size=batch_size,  # 평가 배치 크기 설정\n",
    "                    num_train_epochs=epochs,  # 현재 학습 에포크 수 설정\n",
    "                    weight_decay=0.01,  # 가중치 감쇠 설정\n",
    "                    logging_dir='./logs',  # 로그 저장 경로 설정\n",
    "                    logging_steps=10,  # 로그를 기록할 단계 수 설정\n",
    "                )\n",
    "\n",
    "                # 모델을 학습 모드로 설정\n",
    "                model.train()\n",
    "\n",
    "                # Trainer 생성\n",
    "                trainer = Trainer(\n",
    "                    # model=model, #.to(),\n",
    "                    model=model.to(device),  # 모델을 GPU로 이동\n",
    "                    args=training_args,\n",
    "                    train_dataset=train_dataset,  # 훈련 데이터셋\n",
    "                    eval_dataset=dev_dataset,  # 평가 데이터셋\n",
    "                )\n",
    "\n",
    "                # 모델 학습\n",
    "                trainer.train()\n",
    "\n",
    "                # 훈련 데이터에서 평가\n",
    "                train_results = trainer.predict(train_dataset)\n",
    "                train_preds = np.argmax(train_results.predictions, axis=1)\n",
    "                train_labels = train_results.label_ids\n",
    "                train_accuracy = accuracy_score(train_labels, train_preds)\n",
    "                train_precision = precision_score(train_labels, train_preds, average='binary')\n",
    "                train_recall = recall_score(train_labels, train_preds, average='binary')\n",
    "                train_f1 = f1_score(train_labels, train_preds, average='binary')\n",
    "                train_loss = train_results.metrics['eval_loss'] if 'eval_loss' in train_results.metrics else None\n",
    "\n",
    "                # 테스트 데이터에서 평가\n",
    "                eval_results = trainer.evaluate()\n",
    "                predictions = trainer.predict(dev_dataset)\n",
    "                preds = np.argmax(predictions.predictions, axis=1)\n",
    "                labels = predictions.label_ids\n",
    "                eval_accuracy = accuracy_score(labels, preds)\n",
    "                eval_precision = precision_score(labels, preds, average='binary')\n",
    "                eval_recall = recall_score(labels, preds, average='binary')\n",
    "                eval_f1 = f1_score(labels, preds, average='binary')\n",
    "                eval_loss = eval_results['eval_loss'] if 'eval_loss' in eval_results else None\n",
    "                tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "                eval_specificity = tn / (tn + fp)\n",
    "\n",
    "                # 성능 메트릭 계산\n",
    "                accuracy = accuracy_score(labels, preds)\n",
    "                precision = precision_score(labels, preds, average='binary')\n",
    "                recall = recall_score(labels, preds, average='binary')\n",
    "                f1 = f1_score(labels, preds, average='binary')\n",
    "                tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "                specificity = tn / (tn + fp)\n",
    "\n",
    "                # 결과 저장\n",
    "                results.append({\n",
    "                    'learning_rate': learning_rate,\n",
    "                    'batch_size': batch_size,\n",
    "                    'num_train_epochs': epochs,\n",
    "                    'train_accuracy': train_accuracy,\n",
    "                    'train_precision': train_precision,\n",
    "                    'train_recall': train_recall,\n",
    "                    'train_f1': train_f1,\n",
    "                    'train_loss': train_loss,\n",
    "                    'eval_accuracy': eval_accuracy,\n",
    "                    'eval_precision': eval_precision,\n",
    "                    'eval_recall': eval_recall,\n",
    "                    'eval_f1': eval_f1,\n",
    "                    'eval_loss': eval_loss,\n",
    "                    'eval_specificity': eval_specificity\n",
    "                })\n",
    "\n",
    "                # 최고 성능 모델 기록\n",
    "                if eval_accuracy > best_accuracy:\n",
    "                    best_accuracy = eval_accuracy\n",
    "                    best_F1 = eval_f1\n",
    "                    best_params = {\n",
    "                        'learning_rate': learning_rate,\n",
    "                        'batch_size': batch_size,\n",
    "                        'num_train_epochs': epochs\n",
    "                    }\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error with parameters: learning_rate={learning_rate}, batch_size={batch_size}, epochs={epochs}\")\n",
    "                print(f\"Exception: {e}\")\n",
    "                continue\n",
    "\n",
    "# 최적의 하이퍼파라미터 조합 출력\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)\n",
    "print(\"Best F1:\", best_F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectM4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
