{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/tfGPU/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/tfGPU/lib/python3.9/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/tfGPU/lib/python3.9/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ElectraForSequenceClassification, ElectraTokenizer\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "# from pykospacing import Spacing\n",
    "# import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r'./data/korean-hate-speech-detection/train.hate.csv')\n",
    "\n",
    "train_text = open(r'./data/korean-hate-speech-detection/train.news_title.txt', 'r')\n",
    "train_texts = train_text.readlines()\n",
    "\n",
    "train_text_list = []\n",
    "for line in train_texts:\n",
    "    train_text_list.append(line)\n",
    "train_text.close()\n",
    "\n",
    "train_df['text'] = train_text_list\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengh = []\n",
    "for i in train_df['comments']:\n",
    "    lengh.append(len(i))\n",
    "max(lengh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing = Spacing()\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = spacing(text)\n",
    "    text = text.lower()  # 소문자 변경\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# 기본 불용어 불러오기\n",
    "korean_stopwords_path = \"data/stopwords-ko.txt\"\n",
    "with open(korean_stopwords_path, encoding='utf8') as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [x.strip() for x in stopwords]\n",
    "\n",
    "# 불용어 처리 함수 수정\n",
    "def remove_stopwords(text, stopwords):\n",
    "    words = text.split()  # 문장을 단어로 분리\n",
    "    filtered_text = [word for word in words if word not in stopwords]  # 단어가 불용어 목록에 없는 경우만 추가\n",
    "    return ' '.join(filtered_text)  # 필터링된 단어들 다시 조합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 전처리 및 불용어 처리\n",
    "for i in tqdm(range(len(train_df))):\n",
    "    comment_text = train_df.loc[i, 'comments']\n",
    "    newstile_text = train_df.loc[i, 'text']\n",
    "    processed_comment = preprocessing(comment_text)\n",
    "    processed_newstile = preprocessing(newstile_text)\n",
    "    cleaned_comment = remove_stopwords(processed_comment, stopwords)\n",
    "    cleaned_newstile = remove_stopwords(processed_newstile, stopwords)\n",
    "    train_df.loc[i, 'processed_comments'] = cleaned_comment\n",
    "    train_df.loc[i, 'processed_newstitle'] = cleaned_newstile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['label'] == 'none', 'labels'] = 0\n",
    "train_df.loc[train_df['label'] == 'offensive', 'labels'] = 1\n",
    "train_df.loc[train_df['label'] == 'hate', 'labels'] = 2\n",
    "\n",
    "train_df['labels'] = train_df['labels'].astype(int)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('./data/train_df_processed.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = pd.read_csv(r'./data/korean-hate-speech-detection/dev.hate.csv')\n",
    "\n",
    "dev_text = open(r'./data/korean-hate-speech-detection/dev.news_title.txt', 'r')\n",
    "dev_texts = dev_text.readlines()\n",
    "\n",
    "dev_text_list = []\n",
    "for line in dev_texts:\n",
    "    dev_text_list.append(line)\n",
    "dev_text.close\n",
    "\n",
    "dev_df['text'] = dev_text_list\n",
    "dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 전처리 및 불용어 처리\n",
    "for i in tqdm(range(len(dev_df))):\n",
    "    comment_text = dev_df.loc[i, 'comments']\n",
    "    newstile_text = dev_df.loc[i, 'text']\n",
    "    processed_comment = preprocessing(comment_text)\n",
    "    processed_newstile = preprocessing(newstile_text)\n",
    "    cleaned_comment = remove_stopwords(processed_comment, stopwords)\n",
    "    cleaned_newstile = remove_stopwords(processed_newstile, stopwords)\n",
    "    dev_df.loc[i, 'processed_comments'] = cleaned_comment\n",
    "    dev_df.loc[i, 'processed_newstitle'] = cleaned_newstile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.loc[dev_df['label'] == 'none', 'labels'] = 0\n",
    "dev_df.loc[dev_df['label'] == 'offensive', 'labels'] = 1\n",
    "dev_df.loc[dev_df['label'] == 'hate', 'labels'] = 2\n",
    "dev_df['labels'] = dev_df['labels'].astype(int)\n",
    "\n",
    "dev_df.to_csv('./data/dev_df_processed.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = pd.read_csv('./data/dev_df_processed.csv')\n",
    "dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ㅋㅋㅋㅋ 그래도 조아해주는 팬들 많아서 좋겠다 ㅠㅠ 니들은 온유가 안만져줌 ㅠㅠ</td>\n",
       "      <td>\"샤이니 온유, 클럽 강제추행 '무혐의' 처분 받았다\"\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>둘다 넘 좋다~행복하세요</td>\n",
       "      <td>\"류현경♥︎박성훈, 공개연애 4년차 애정전선 이상無..\"\"의지 많이 된다\"\"[종합]\"\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데</td>\n",
       "      <td>\"\"\"현금 유도+1인 1라면?\"\"…'골목식당' 백종원, 초심 잃은 도시락집에 '경악...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>원곡생각하나도 안나고 러블리즈 신곡나온줄!!! 너무 예쁘게 잘봤어요</td>\n",
       "      <td>\"'슈가맨3' 애즈원, 87불 최다 기록…'슬픈 얼굴' ART 소환 완료 [종합]\"\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>장현승 얘도 참 이젠 짠하다...</td>\n",
       "      <td>\"[엑's 리뷰] \"\"♥장현승\"\"...신수지, 사랑 앞에 당당한 쿨한 언니\"\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>대박 게스트... 꼭 봐야징~ 컨셉이 바뀌니깐 재미지넹</td>\n",
       "      <td>\"'해투4' 이서진, 한지민 '대본 리딩 격리설' 해명…\"\"날씨가 좋아서\"\" [SC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>성형으로 다 뜯어고쳐놓고 예쁜척. 성형 전 니 얼굴 다 알고있다. 순자처럼 된장냄새...</td>\n",
       "      <td>\"[SS인터뷰①]박민영 \"\"'김비서' 행복했다..열애설엔 당당..미소였으니까\"\"\"\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>분위기는 비슷하다만 전혀다른 전개던데 무슨ㅋㅋㄱ 우리나라사람들은 분위기만 비슷하면 ...</td>\n",
       "      <td>\"[POP이슈]\"\"사실무근\"\" 'SKY캐슬' 측 '위올라이' 표절설 부인→여전히 '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>입에 손가릭이 10개 있으니 징그럽다</td>\n",
       "      <td>\"'오창석♥' 이채은, 웨딩사진?...순백의 드레스 입고 '활짝'\"\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>난 조보아 이뻐서 보는데 백종원 관심무</td>\n",
       "      <td>\"[단독]'골목식당'PD \"\"1위 비결은 백종원 진심, 대본無 리얼 솔루션\"\"(인터...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>974 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comments  \\\n",
       "0         ㅋㅋㅋㅋ 그래도 조아해주는 팬들 많아서 좋겠다 ㅠㅠ 니들은 온유가 안만져줌 ㅠㅠ   \n",
       "1                                        둘다 넘 좋다~행복하세요   \n",
       "2                 근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데   \n",
       "3                원곡생각하나도 안나고 러블리즈 신곡나온줄!!! 너무 예쁘게 잘봤어요   \n",
       "4                                   장현승 얘도 참 이젠 짠하다...   \n",
       "..                                                 ...   \n",
       "969                     대박 게스트... 꼭 봐야징~ 컨셉이 바뀌니깐 재미지넹   \n",
       "970  성형으로 다 뜯어고쳐놓고 예쁜척. 성형 전 니 얼굴 다 알고있다. 순자처럼 된장냄새...   \n",
       "971  분위기는 비슷하다만 전혀다른 전개던데 무슨ㅋㅋㄱ 우리나라사람들은 분위기만 비슷하면 ...   \n",
       "972                               입에 손가릭이 10개 있으니 징그럽다   \n",
       "973                              난 조보아 이뻐서 보는데 백종원 관심무   \n",
       "\n",
       "                                                  text  \n",
       "0                     \"샤이니 온유, 클럽 강제추행 '무혐의' 처분 받았다\"\\n  \n",
       "1    \"류현경♥︎박성훈, 공개연애 4년차 애정전선 이상無..\"\"의지 많이 된다\"\"[종합]\"\\n  \n",
       "2    \"\"\"현금 유도+1인 1라면?\"\"…'골목식당' 백종원, 초심 잃은 도시락집에 '경악...  \n",
       "3     \"'슈가맨3' 애즈원, 87불 최다 기록…'슬픈 얼굴' ART 소환 완료 [종합]\"\\n  \n",
       "4         \"[엑's 리뷰] \"\"♥장현승\"\"...신수지, 사랑 앞에 당당한 쿨한 언니\"\\n  \n",
       "..                                                 ...  \n",
       "969  \"'해투4' 이서진, 한지민 '대본 리딩 격리설' 해명…\"\"날씨가 좋아서\"\" [SC...  \n",
       "970    \"[SS인터뷰①]박민영 \"\"'김비서' 행복했다..열애설엔 당당..미소였으니까\"\"\"\\n  \n",
       "971  \"[POP이슈]\"\"사실무근\"\" 'SKY캐슬' 측 '위올라이' 표절설 부인→여전히 '...  \n",
       "972            \"'오창석♥' 이채은, 웨딩사진?...순백의 드레스 입고 '활짝'\"\\n  \n",
       "973  \"[단독]'골목식당'PD \"\"1위 비결은 백종원 진심, 대본無 리얼 솔루션\"\"(인터...  \n",
       "\n",
       "[974 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(r'./data/korean-hate-speech-detection/test.hate.no_label.csv')\n",
    "\n",
    "test_text = open(r'./data/korean-hate-speech-detection/test.news_title.txt')\n",
    "test_texts = test_text.readlines()\n",
    "test_text_list = []\n",
    "for line in test_texts:\n",
    "    test_text_list.append(line)\n",
    "\n",
    "test_df['text'] = test_text_list\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 전처리 및 불용어 처리\n",
    "for i in tqdm(range(len(test_df))):\n",
    "    comment_text = test_df.loc[i, 'comments']\n",
    "    newstile_text = test_df.loc[i, 'text']\n",
    "    processed_comment = preprocessing(comment_text)\n",
    "    processed_newstile = preprocessing(newstile_text)\n",
    "    cleaned_comment = remove_stopwords(processed_comment, stopwords)\n",
    "    cleaned_newstile = remove_stopwords(processed_newstile, stopwords)\n",
    "    test_df.loc[i, 'processed_comments'] = cleaned_comment\n",
    "    test_df.loc[i, 'processed_newstitle'] = cleaned_newstile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('./data/test_df_processed.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r'./data/train_df_processed.csv')\n",
    "dev_df = pd.read_csv(r'./data/dev_df_processed.csv')\n",
    "test_df = pd.read_csv(r'./data/test_df_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 정의 시, labels가 시리즈 형태라 오류 발생하여, tolist() 추가\n",
    "# 해도 오류라서 먼저 변경 해봄.\n",
    "train_title_list = train_df['text'].tolist()\n",
    "train_comment_list = train_df['comments'].tolist()\n",
    "train_label_list = train_df['labels'].astype(int).tolist()\n",
    "dev_title_list = dev_df['text'].tolist()\n",
    "dev_comment_list = dev_df['comments'].tolist()\n",
    "dev_label_list = dev_df['labels'].astype(int).tolist()\n",
    "print(type(train_label_list))\n",
    "print(type(dev_label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'beomi/KcELECTRA-base-v2022'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스 정의\n",
    "class TitleCommentDataset(Dataset):\n",
    "    def __init__(self, titles, comments, labels, tokenizer, max_length=256):\n",
    "        self.titles = titles\n",
    "        self.comments = comments\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, list):\n",
    "            return self.get_batch(idx)\n",
    "        return self.get_single_item(idx)\n",
    "    \n",
    "    def get_single_item(self, idx):\n",
    "        title = self.titles[idx]\n",
    "        comment = self.comments[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # 제목과 댓글을 특별 토큰으로 구분하여 결합\n",
    "        text = f'{title} [SEP] {comment}'\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "    def get_batch(self, indices):\n",
    "        batch = {\n",
    "            'input_ids': [],\n",
    "            'attention_mask': [],\n",
    "            'labels': [],\n",
    "        }\n",
    "        for idx in indices:\n",
    "            item = self.get_single_item(idx)\n",
    "            for key in batch:\n",
    "                batch[key].append(item[key])\n",
    "    \n",
    "        return {key: torch.stack(batch[key]) for key in batch}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할 및 데이터로더 생성\n",
    "train_dataset = TitleCommentDataset(train_title_list, train_comment_list, train_label_list, tokenizer)\n",
    "val_dataset = TitleCommentDataset(dev_title_list, dev_comment_list, dev_label_list, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수 정의\n",
    "def train(model, train_loader, val_loader, epochs=3):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # 검증\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                val_loss += outputs.loss.item()\n",
    "                _, predicted = torch.max(outputs.logits, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_accuracy = correct / total\n",
    "        print(f'Epoch {epoch+1}/{epoch}, Val Loss: {val_loss/len(val_loader):.4f}, Val Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 수행\n",
    "def evaluate_model(model, val_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # 정확도 계산\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    # F1 스코어 계산\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "    # 혼동 행렬 계산 및 시각화\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1, 2])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    disp.plot(ax=ax)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# 모델 평가 실행\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "evaluate_model(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "def make_tensors_contiguous(model):\n",
    "    for param in model.parameters():\n",
    "        param.data = param.data.contiguous()\n",
    "\n",
    "# 모델 저장 전에 호출\n",
    "make_tensors_contiguous(model)\n",
    "model.save_pretrained('./saved_model')\n",
    "tokenizer.save_pretrained('./saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 함수 정의\n",
    "def predict(title, comment):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    text = f\"{title} [SEP] {comment}\"\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=256,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "    \n",
    "    return predicted.item()  # 0, 1, 또는 2를 반환\n",
    "    \n",
    "# 예측 결과를 저장할 새로운 컬럼 생성\n",
    "test_df['predicted_label'] = None\n",
    "\n",
    "# tqdm을 사용하여 진행 상황 표시\n",
    "for index, row in tqdm(test_df.iterrows(), total=test_df.shape[0]):\n",
    "    title = row['text']  # CSV 파일의 제목 컬럼 이름\n",
    "    comment = row['comments']  # CSV 파일의 댓글 컬럼 이름\n",
    "    \n",
    "    # 예측 수행\n",
    "    predicted_label = predict(title, comment)\n",
    "    \n",
    "    # 예측 결과를 DataFrame에 저장\n",
    "    test_df.at[index, 'predicted_label'] = predicted_label\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "test_df.to_csv('./data/save_results.csv', index=False)\n",
    "\n",
    "print(\"예측이 완료되었고 결과가 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_comments</th>\n",
       "      <th>processed_newstitle</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ㅋㅋㅋㅋ 그래도 조아해주는 팬들 많아서 좋겠다 ㅠㅠ 니들은 온유가 안만져줌 ㅠㅠ</td>\n",
       "      <td>\"샤이니 온유, 클럽 강제추행 '무혐의' 처분 받았다\"\\n</td>\n",
       "      <td>ㅋㅋㅋㅋ 조아해주는 팬들 많아서 좋겠다 ㅠㅠ 니들은 온유가 안 만져줌 ㅠㅠ</td>\n",
       "      <td>샤이니 온유 클럽 강제추행 무혐의 처분 받았다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>둘다 넘 좋다~행복하세요</td>\n",
       "      <td>\"류현경♥︎박성훈, 공개연애 4년차 애정전선 이상無..\"\"의지 많이 된다\"\"[종합]\"\\n</td>\n",
       "      <td>다 넘 좋다행복하세요</td>\n",
       "      <td>류현경 박성훈 공개연애 4년차 애정전선 이상無 의지 많이 된다종합</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데</td>\n",
       "      <td>\"\"\"현금 유도+1인 1라면?\"\"…'골목식당' 백종원, 초심 잃은 도시락집에 '경악...</td>\n",
       "      <td>근데 만 원 이하는 현금 결제만 하라고 써놓은 집 우리나라에 엄청 많은데</td>\n",
       "      <td>현금 유도1인 1라면 골목식당 백종원 초심 잃은 도시락 집에 경악 종합</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>원곡생각하나도 안나고 러블리즈 신곡나온줄!!! 너무 예쁘게 잘봤어요</td>\n",
       "      <td>\"'슈가맨3' 애즈원, 87불 최다 기록…'슬픈 얼굴' ART 소환 완료 [종합]\"\\n</td>\n",
       "      <td>원곡생각 하나도 안 나고 러블리즈 신곡나온 줄 너무 예쁘게 잘 봤어요</td>\n",
       "      <td>슈가맨3 애즈원 87불 최다 기록 슬픈 얼굴 art 소환 완료 종합</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>장현승 얘도 참 이젠 짠하다...</td>\n",
       "      <td>\"[엑's 리뷰] \"\"♥장현승\"\"...신수지, 사랑 앞에 당당한 쿨한 언니\"\\n</td>\n",
       "      <td>장현승 얘도 짠하다</td>\n",
       "      <td>엑s 리뷰 장현승신수지 사랑 앞에 당당한 쿨한 언니</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>대박 게스트... 꼭 봐야징~ 컨셉이 바뀌니깐 재미지넹</td>\n",
       "      <td>\"'해투4' 이서진, 한지민 '대본 리딩 격리설' 해명…\"\"날씨가 좋아서\"\" [SC...</td>\n",
       "      <td>대박 게스트 꼭 봐야 징 컨셉이 바뀌니깐 재미지넹</td>\n",
       "      <td>해투4 서진 한지민 대본 리딩 격리설 해명 날씨가 좋아서 sc컷</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>성형으로 다 뜯어고쳐놓고 예쁜척. 성형 전 니 얼굴 다 알고있다. 순자처럼 된장냄새...</td>\n",
       "      <td>\"[SS인터뷰①]박민영 \"\"'김비서' 행복했다..열애설엔 당당..미소였으니까\"\"\"\\n</td>\n",
       "      <td>성형으로 다 뜯어고쳐 놓고 예쁜 척 성형 전 니 얼굴 다 알고 순자처럼 된장 냄새나...</td>\n",
       "      <td>ss인터뷰①박민영 김 비서 행복했다열애설엔 당당미소였으니까</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>분위기는 비슷하다만 전혀다른 전개던데 무슨ㅋㅋㄱ 우리나라사람들은 분위기만 비슷하면 ...</td>\n",
       "      <td>\"[POP이슈]\"\"사실무근\"\" 'SKY캐슬' 측 '위올라이' 표절설 부인→여전히 '...</td>\n",
       "      <td>분위기는 만 전혀 전개 던데 ㅋㅋㄱ 우리나라 사람들은 분위기만 비슷하면 다 표절 클...</td>\n",
       "      <td>pop 이슈사실무근 sky캐슬 측 위올라이 표절 설 부인 핫종합</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>입에 손가릭이 10개 있으니 징그럽다</td>\n",
       "      <td>\"'오창석♥' 이채은, 웨딩사진?...순백의 드레스 입고 '활짝'\"\\n</td>\n",
       "      <td>입에 손가릭이 10개 있으니 징그럽다</td>\n",
       "      <td>오창석 이채은 웨딩 사진순백의 드레스 입고 활짝</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>난 조보아 이뻐서 보는데 백종원 관심무</td>\n",
       "      <td>\"[단독]'골목식당'PD \"\"1위 비결은 백종원 진심, 대본無 리얼 솔루션\"\"(인터...</td>\n",
       "      <td>난 조 보아 뻐서 보는데 백종원 관심무</td>\n",
       "      <td>단독골목식당 pd 1위 비결은 백종원 진심 대본無 리얼 솔루션인터뷰</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>974 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comments  \\\n",
       "0         ㅋㅋㅋㅋ 그래도 조아해주는 팬들 많아서 좋겠다 ㅠㅠ 니들은 온유가 안만져줌 ㅠㅠ   \n",
       "1                                        둘다 넘 좋다~행복하세요   \n",
       "2                 근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데   \n",
       "3                원곡생각하나도 안나고 러블리즈 신곡나온줄!!! 너무 예쁘게 잘봤어요   \n",
       "4                                   장현승 얘도 참 이젠 짠하다...   \n",
       "..                                                 ...   \n",
       "969                     대박 게스트... 꼭 봐야징~ 컨셉이 바뀌니깐 재미지넹   \n",
       "970  성형으로 다 뜯어고쳐놓고 예쁜척. 성형 전 니 얼굴 다 알고있다. 순자처럼 된장냄새...   \n",
       "971  분위기는 비슷하다만 전혀다른 전개던데 무슨ㅋㅋㄱ 우리나라사람들은 분위기만 비슷하면 ...   \n",
       "972                               입에 손가릭이 10개 있으니 징그럽다   \n",
       "973                              난 조보아 이뻐서 보는데 백종원 관심무   \n",
       "\n",
       "                                                  text  \\\n",
       "0                     \"샤이니 온유, 클럽 강제추행 '무혐의' 처분 받았다\"\\n   \n",
       "1    \"류현경♥︎박성훈, 공개연애 4년차 애정전선 이상無..\"\"의지 많이 된다\"\"[종합]\"\\n   \n",
       "2    \"\"\"현금 유도+1인 1라면?\"\"…'골목식당' 백종원, 초심 잃은 도시락집에 '경악...   \n",
       "3     \"'슈가맨3' 애즈원, 87불 최다 기록…'슬픈 얼굴' ART 소환 완료 [종합]\"\\n   \n",
       "4         \"[엑's 리뷰] \"\"♥장현승\"\"...신수지, 사랑 앞에 당당한 쿨한 언니\"\\n   \n",
       "..                                                 ...   \n",
       "969  \"'해투4' 이서진, 한지민 '대본 리딩 격리설' 해명…\"\"날씨가 좋아서\"\" [SC...   \n",
       "970    \"[SS인터뷰①]박민영 \"\"'김비서' 행복했다..열애설엔 당당..미소였으니까\"\"\"\\n   \n",
       "971  \"[POP이슈]\"\"사실무근\"\" 'SKY캐슬' 측 '위올라이' 표절설 부인→여전히 '...   \n",
       "972            \"'오창석♥' 이채은, 웨딩사진?...순백의 드레스 입고 '활짝'\"\\n   \n",
       "973  \"[단독]'골목식당'PD \"\"1위 비결은 백종원 진심, 대본無 리얼 솔루션\"\"(인터...   \n",
       "\n",
       "                                    processed_comments  \\\n",
       "0            ㅋㅋㅋㅋ 조아해주는 팬들 많아서 좋겠다 ㅠㅠ 니들은 온유가 안 만져줌 ㅠㅠ   \n",
       "1                                          다 넘 좋다행복하세요   \n",
       "2             근데 만 원 이하는 현금 결제만 하라고 써놓은 집 우리나라에 엄청 많은데   \n",
       "3               원곡생각 하나도 안 나고 러블리즈 신곡나온 줄 너무 예쁘게 잘 봤어요   \n",
       "4                                           장현승 얘도 짠하다   \n",
       "..                                                 ...   \n",
       "969                        대박 게스트 꼭 봐야 징 컨셉이 바뀌니깐 재미지넹   \n",
       "970  성형으로 다 뜯어고쳐 놓고 예쁜 척 성형 전 니 얼굴 다 알고 순자처럼 된장 냄새나...   \n",
       "971  분위기는 만 전혀 전개 던데 ㅋㅋㄱ 우리나라 사람들은 분위기만 비슷하면 다 표절 클...   \n",
       "972                               입에 손가릭이 10개 있으니 징그럽다   \n",
       "973                              난 조 보아 뻐서 보는데 백종원 관심무   \n",
       "\n",
       "                         processed_newstitle  predicted_label  \n",
       "0                  샤이니 온유 클럽 강제추행 무혐의 처분 받았다                1  \n",
       "1       류현경 박성훈 공개연애 4년차 애정전선 이상無 의지 많이 된다종합                0  \n",
       "2    현금 유도1인 1라면 골목식당 백종원 초심 잃은 도시락 집에 경악 종합                0  \n",
       "3      슈가맨3 애즈원 87불 최다 기록 슬픈 얼굴 art 소환 완료 종합                0  \n",
       "4               엑s 리뷰 장현승신수지 사랑 앞에 당당한 쿨한 언니                0  \n",
       "..                                       ...              ...  \n",
       "969      해투4 서진 한지민 대본 리딩 격리설 해명 날씨가 좋아서 sc컷                0  \n",
       "970         ss인터뷰①박민영 김 비서 행복했다열애설엔 당당미소였으니까                2  \n",
       "971      pop 이슈사실무근 sky캐슬 측 위올라이 표절 설 부인 핫종합                1  \n",
       "972               오창석 이채은 웨딩 사진순백의 드레스 입고 활짝                2  \n",
       "973    단독골목식당 pd 1위 비결은 백종원 진심 대본無 리얼 솔루션인터뷰                0  \n",
       "\n",
       "[974 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.read_csv('./data/save_results.csv')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df.drop(['text', 'processed_comments', 'processed_newstitle'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df.rename(columns={'predicted_label':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('./data/results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectM4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
