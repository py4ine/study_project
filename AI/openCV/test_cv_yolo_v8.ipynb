{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.utils import LOGGER\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# yolo 로그 메시지 비활성화\n",
    "LOGGER.disabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv8 모델 로드 (사전 학습된 COCO 데이터셋 사용)\n",
    "model = YOLO('yolov8n.pt')  # 'yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt' 중 선택 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 로컬 영상 파일 열기\n",
    "video_path = '../../../Data/video/1-1_006-C04.mp4'\n",
    "url = 'rtsp://210.99.70.120:1935/live/cctv002.stream'\n",
    "cap = cv2.VideoCapture(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영상시작\n",
      "object_id 7_262_104_314_167\n",
      "object_tracks[object_id] (288, 135)\n",
      "prev_center_x 288\n",
      "prev_center_y 135\n",
      "객체 7_262_104_314_167: prev_center_y=135, center_y=135, mid_y=240\n",
      "object_id 7_262_104_314_167\n",
      "object_tracks[object_id] (288, 135)\n",
      "prev_center_x 288\n",
      "prev_center_y 135\n",
      "객체 7_262_104_314_167: prev_center_y=135, center_y=135, mid_y=240\n",
      "object_id 7_262_103_320_166\n",
      "object_tracks[object_id] (291, 134)\n",
      "prev_center_x 291\n",
      "prev_center_y 134\n",
      "객체 7_262_103_320_166: prev_center_y=134, center_y=134, mid_y=240\n",
      "object_id 7_262_103_320_166\n",
      "object_tracks[object_id] (291, 134)\n",
      "prev_center_x 291\n",
      "prev_center_y 134\n",
      "객체 7_262_103_320_166: prev_center_y=134, center_y=134, mid_y=240\n",
      "object_id 7_262_103_320_166\n",
      "object_tracks[object_id] (291, 134)\n",
      "prev_center_x 291\n",
      "prev_center_y 134\n",
      "객체 7_262_103_320_166: prev_center_y=134, center_y=134, mid_y=240\n",
      "object_id 7_262_104_314_166\n",
      "object_tracks[object_id] (288, 135)\n",
      "prev_center_x 288\n",
      "prev_center_y 135\n",
      "객체 7_262_104_314_166: prev_center_y=135, center_y=135, mid_y=240\n",
      "object_id 7_262_104_316_166\n",
      "object_tracks[object_id] (289, 135)\n",
      "prev_center_x 289\n",
      "prev_center_y 135\n",
      "객체 7_262_104_316_166: prev_center_y=135, center_y=135, mid_y=240\n",
      "object_id 7_262_104_312_166\n",
      "object_tracks[object_id] (287, 135)\n",
      "prev_center_x 287\n",
      "prev_center_y 135\n",
      "객체 7_262_104_312_166: prev_center_y=135, center_y=135, mid_y=240\n"
     ]
    }
   ],
   "source": [
    "# 3. 프레임별 처리\n",
    "object_tracks = {}  # 객체 위치 저장용 딕셔너리\n",
    "TARGET_CLASS = [2, 5, 7]\n",
    "count_num = 0\n",
    "\n",
    "frame_count = 0\n",
    "skip_frames = 5  # 5프레임마다 한 번씩 처리\n",
    "\n",
    "print(\"영상시작\")\n",
    "\n",
    "# 첫 번째 프레임에서 프레임 크기 초기화\n",
    "ret, frame = cap.read()\n",
    "if not ret:  # 첫 번째 프레임 읽기 실패 시 프로그램 종료\n",
    "    print(\"비디오 파일을 읽을 수 없습니다.\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "frame_height, frame_width = frame.shape[:2]\n",
    "mid_x = frame_width // 2  # 화면 중간 x좌표 계산\n",
    "mid_y = frame_height // 2  # 화면 중간 y좌표 계산\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    if frame_count % skip_frames != 0:  # 프레임 스킵\n",
    "        continue\n",
    "    if frame_count % 1000 == 0:  # 1000프레임마다 스트림 재연결\n",
    "        print(\"스트림 초기화\")\n",
    "        cap.release()\n",
    "        cap = cv2.VideoCapture(url)\n",
    "\n",
    "    # YOLOv8 객체 탐지\n",
    "    results = model(frame)\n",
    "    detections = results[0].boxes\n",
    "\n",
    "    # 현재 프레임에서 탐지된 객체 정보 저장\n",
    "    current_frame_tracks = {}\n",
    "    threshold = frame_height // 20  # 중앙선 근처 허용 오차\n",
    "\n",
    "    for det in detections:\n",
    "        x1, y1, x2, y2 = map(int, det.xyxy[0].tolist())  # 경계 상자 좌표\n",
    "        confidence = det.conf[0]  # 신뢰도\n",
    "        class_id = int(det.cls[0])  # 클래스id\n",
    "\n",
    "        if confidence > 0.5 and class_id in TARGET_CLASS:\n",
    "            center_x = int((x1 + x2) / 2)\n",
    "            center_y = int((y1 + y2) / 2)\n",
    "\n",
    "            # object_id =  hash(f\"{class_id}_{center_x}_{center_y}\")  # 고유 ID 생성\n",
    "            object_id = f\"{class_id}_{x1}_{y1}_{x2}_{y2}\"\n",
    "            current_frame_tracks[object_id] = (center_x, center_y)\n",
    "\n",
    "            #이전 위치와 비교하여 이동 방향 계산\n",
    "            if object_id in object_tracks:\n",
    "                prev_center_x, prev_center_y = object_tracks[object_id]\n",
    "                print(\"object_id\", object_id)\n",
    "                print(\"object_tracks[object_id]\", object_tracks[object_id])\n",
    "                print(\"prev_center_x\", prev_center_x)\n",
    "                print(\"prev_center_y\", prev_center_y)\n",
    "\n",
    "                 # 디버깅: 객체 이동 방향 확인\n",
    "                print(f\"객체 {object_id}: prev_center_y={prev_center_y}, center_y={center_y}, mid_y={mid_y}\")\n",
    "\n",
    "                # 위쪽-> 아래쪽 이동\n",
    "                if prev_center_y < mid_y - threshold and center_y >= mid_y + threshold:\n",
    "                    count_num += 1\n",
    "                    print(f\"객체 {object_id}가 위쪽에서 아래쪽으로 이동. 현재 인원수: {count_num}\")\n",
    "\n",
    "                # 아래쪽 -> 위쪽 이동\n",
    "                elif prev_center_y > mid_y + threshold and center_y <= mid_y - threshold:\n",
    "                    count_num -= 1\n",
    "                    print(f\"객체 {object_id}가 아래쪽에서 위쪽으로 이동. 현재 인원수: {count_num}\")\n",
    "\n",
    "            # 현재 위치 업데이트\n",
    "            # object_tracks[object_id] = (center_x, center_y)\n",
    "            object_tracks.update(current_frame_tracks)\n",
    "\n",
    "            # 경계 상자 및 중심점 표시\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "            cv2.circle(frame, (center_x, center_y), 5, (255,0, 0), -1)\n",
    "    \n",
    "    # # 객체 이동 방향 업데이트\n",
    "    object_tracks = current_frame_tracks            \n",
    "    \n",
    "    \n",
    "    # 영상 중간 부분에 세로선 그리기\n",
    "    # cv2.line(frame, (mid_x, 0), (mid_x, frame_width), (255, 0, 0), 2)  # (255, 0, 0)은 파란색, 두께는 2\n",
    "    \n",
    "    # 영상 중간 부분에 가로선 그리기\n",
    "    cv2.line(frame, (0, mid_y), (frame_width, mid_y), (255, 0, 0), 1)  # (255, 0, 0)은 파란색, 두께는 2\n",
    "\n",
    "    # 프레임 보여주기\n",
    "    cv2.imshow('Detection', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
