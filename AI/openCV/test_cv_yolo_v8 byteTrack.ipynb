{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolox.tracker.byte_tracker import BYTETracker\n",
    "from yolox.utils.visualize import plot_tracking\n",
    "# from bytetrack import BYTETracker\n",
    "from ultralytics.utils import LOGGER\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# yolo 로그 메시지 비활성화\n",
    "LOGGER.disabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv8 모델 로드 (사전 학습된 COCO 데이터셋 사용)\n",
    "model = YOLO('yolov8n.pt')  # 'yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt' 중 선택 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ByteTrack 설정\n",
    "tracker_args = {\n",
    "    'track_thresh': 0.3,\n",
    "    'high_thresh': 0.6, \n",
    "    'match_thresh': 0.8,\n",
    "    'track_buffer': 30,\n",
    "    'mot20': False\n",
    "}\n",
    "\n",
    "# 딕셔너리를 Namespace로 변환\n",
    "from argparse import Namespace\n",
    "tracker_args = Namespace(**tracker_args)\n",
    "\n",
    "# # BYTETracker 클래스 내부에서 딕셔너리 처리\n",
    "# class BYTETracker:\n",
    "#     def __init__(self, args, frame_rate=30):\n",
    "#         # 딕셔너리로 처리\n",
    "#         self.det_thresh = args['track_thresh'] + 0.1\n",
    "#         self.buffer_size = int(frame_rate / 30.0 * args['track_buffer'])\n",
    "#         self.max_time_lost = self.buffer_size\n",
    "#         # 기타 초기화 코드\n",
    "\n",
    "tracker = BYTETracker(tracker_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 로컬 영상 파일 열기\n",
    "video_path = '../../../Data/video/1-1_601-C09.mp4'\n",
    "url = 'rtsp://210.99.70.120:1935/live/cctv002.stream'\n",
    "cap = cv2.VideoCapture(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480 720\n",
      "영상시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda3\\envs\\p2\\lib\\site-packages\\yolox\\tracker\\byte_tracker.py:182: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen/native/IndexingUtils.h:28.)\n",
      "  dets_second = bboxes[inds_second]\n",
      "c:\\miniconda3\\envs\\p2\\lib\\site-packages\\yolox\\tracker\\byte_tracker.py:185: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen/native/IndexingUtils.h:28.)\n",
      "  scores_second = scores[inds_second]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "객체 244가 아래쪽에서 위쪽으로 이동. 현재 인원수: -1\n"
     ]
    }
   ],
   "source": [
    "# 3. 프레임별 처리\n",
    "object_tracks = {}  # 객체 위치 저장용 딕셔너리\n",
    "count_num = 0\n",
    "TARGET_CLASS = [2, 5, 7]\n",
    "\n",
    "frame_count = 0\n",
    "skip_frames = 5  # 5프레임마다 한 번씩 처리\n",
    "\n",
    "# 첫 번째 프레임에서 프레임 크기 초기화\n",
    "ret, frame = cap.read()\n",
    "if not ret:  # 첫 번째 프레임 읽기 실패 시 프로그램 종료\n",
    "    print(\"비디오 파일을 읽을 수 없습니다.\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "frame_height, frame_width = frame.shape[:2]\n",
    "print(frame_height, frame_width)\n",
    "mid_x = frame_width // 2  # 화면 중간 x좌표 계산\n",
    "mid_y = frame_height // 2  # 화면 중간 y좌표 계산\n",
    "\n",
    "print(\"영상시작\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    if frame_count % skip_frames != 0:  # 프레임 스킵\n",
    "        continue\n",
    "    if frame_count % 1000 == 0:  # 1000프레임마다 스트림 재연결\n",
    "        print(\"스트림 초기화\")\n",
    "        cap.release()\n",
    "        cap = cv2.VideoCapture(url)\n",
    "\n",
    "    # YOLOv8 객체 탐지\n",
    "    results = model(frame)\n",
    "    detections = []\n",
    "\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            # print(\"box\", box)\n",
    "            x1, y1, x2, y2 = box.xyxy[0].tolist() #map(float, box.xyxy[0].tolist())  # 좌표를 계산하는 부분\n",
    "            confidence = float(box.conf[0])  # tensor -> float 변환  # 신뢰도\n",
    "            class_id = int(box.cls[0])  # 클래스id\n",
    "            if confidence > 0.5 and class_id in TARGET_CLASS:  # 신뢰도 필터링\n",
    "                detections.append([x1, y1, x2, y2, confidence, class_id])  # [x1, y1, x2, y2, confidence, class_id]\n",
    "    \n",
    "    # ByteTrack 추적\n",
    "    img_info = (frame_height, frame_width)  # 이미지 정보\n",
    "    img_size = (frame_width, frame_height)  # 이미지 크기\n",
    "\n",
    "    if len(detections) == 0:\n",
    "        detection_array = np.empty((0, 5), dtype=float)  # 빈 배열 생성\n",
    "    else:\n",
    "        detection_array = np.array(detections, dtype=float)  # 넘파이 버전 이슈로 dtype수정\n",
    "    # print(f\"detections: {detections}\")\n",
    "    detection_tensor = torch.from_numpy(detection_array).type(torch.float32)  # numpy 배열을 PyTorch Tensor로 변환\n",
    "    online_targets = tracker.update(detection_tensor, img_info, img_size)\n",
    "    \n",
    "    # 추적 결과 시각화\n",
    "    for target in online_targets:\n",
    "        # print(\"target.tlwh:\", target.tlwh)\n",
    "        x1, y1, w, h = target.tlwh  # 바운딩 박스 좌표 및 크기\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x1 + w), int(y1 + h)  # 박스 좌표 변환\n",
    "\n",
    "        # YOLO 모델의 입력 이미지 크기 (전처리 시 사용한 크기)\n",
    "        input_width, input_height = 1080, 720  # 모델 입력 크기를 가져옴\n",
    "        # 이미지 크기 비율 계산\n",
    "        scale_x = frame_width / input_width  # 가로 비율\n",
    "        scale_y = frame_height / input_height  # 세로 비율\n",
    "        # 원본 이미지 크기에 맞게 좌표 변환\n",
    "        x1 = int(x1 * scale_x)\n",
    "        y1 = int(y1 * scale_y)\n",
    "        x2 = int(x2 * scale_x)\n",
    "        y2 = int(y2 * scale_y)\n",
    "        scale_w = int(w * scale_x)\n",
    "        scale_h = int(h * scale_y)\n",
    "\n",
    "        # 중심점 계산\n",
    "        center_x = int(x1 + scale_w / 2)\n",
    "        center_y = int(y1 + scale_h / 2)\n",
    "        \n",
    "        # 고유 객체 ID (ByteTrack에서 track_id 사용)\n",
    "        object_id = target.track_id\n",
    "\n",
    "        # 이전 위치와 비교하여 이동 방향 계산\n",
    "        if object_id in object_tracks:\n",
    "            prev_center_x, prev_center_y = object_tracks[object_id]\n",
    "\n",
    "            # 디버깅 출력\n",
    "            # print(f\"객체 {object_id}: prev_center_y={prev_center_y}, center_y={center_y}, mid_y={mid_y}\")\n",
    "\n",
    "            # 위쪽 → 아래쪽 이동\n",
    "            if prev_center_y < mid_y and center_y >= mid_y:\n",
    "                count_num += 1\n",
    "                print(f\"객체 {object_id}가 위쪽에서 아래쪽으로 이동. 현재 인원수: {count_num}\")\n",
    "\n",
    "            # 아래쪽 → 위쪽 이동\n",
    "            elif prev_center_y > mid_y and center_y <= mid_y:\n",
    "                count_num -= 1\n",
    "                print(f\"객체 {object_id}가 아래쪽에서 위쪽으로 이동. 현재 인원수: {count_num}\")\n",
    "\n",
    "        # 현재 위치 저장\n",
    "        object_tracks[object_id] = (center_x, center_y)\n",
    "        \n",
    "        # 바운딩 박스 그리기\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"ID: {object_id}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        cv2.circle(frame, (center_x, center_y), 5, (0, 255, 0), -1)  # 중심점 표시\n",
    "    \n",
    "    # 영상 중간 부분에 가로선 그리기\n",
    "    cv2.line(frame, (0, mid_y), (frame_width, mid_y), (255, 0, 0), 1)  # (255, 0, 0)은 파란색, 두께는 1\n",
    "    \n",
    "    # 현재 카운팅 값을 화면에 표시\n",
    "    cv2.putText(frame, f\"Count: {count_num}\", (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    \n",
    "    # 프레임 보여주기\n",
    "    cv2.imshow('Detection', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
