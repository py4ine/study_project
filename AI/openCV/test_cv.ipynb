{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "model = tf.saved_model.load('../../../Data/COCO-SSD_Mobilenet_V2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 로컬 영상 파일 열기\n",
    "video_path = '../../../Data/video/1-1_608-C05.mp4'\n",
    "cap = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영상시작\n",
      "Detections: [[663.0, 253.0, 916.0, 853.0, 0.6391046643257141]]\n",
      "Detections: [[711.0, 230.0, 946.0, 828.0, 0.6060701608657837]]\n",
      "Detections: [[711.0, 230.0, 946.0, 828.0, 0.6060701608657837], [769.0, 244.0, 923.0, 706.0, 0.5302690863609314]]\n",
      "Detections: [[870.0, 235.0, 1113.0, 828.0, 0.6295047998428345]]\n",
      "Detections: [[870.0, 235.0, 1113.0, 828.0, 0.6295047998428345], [900.0, 232.0, 1066.0, 685.0, 0.5551256537437439]]\n",
      "Detections: [[975.0, 231.0, 1118.0, 690.0, 0.5375898480415344]]\n",
      "Detections: [[975.0, 231.0, 1118.0, 690.0, 0.5375898480415344], [939.0, 213.0, 1151.0, 830.0, 0.524494469165802]]\n",
      "Detections: [[994.0, 215.0, 1206.0, 822.0, 0.5405222773551941]]\n",
      "Detections: [[1046.0, 218.0, 1291.0, 822.0, 0.5152407884597778]]\n",
      "Detections: [[1083.0, 209.0, 1315.0, 796.0, 0.6488387584686279]]\n",
      "Detections: [[1175.0, 216.0, 1333.0, 645.0, 0.6329004764556885]]\n",
      "Detections: [[1175.0, 216.0, 1333.0, 645.0, 0.6329004764556885], [1147.0, 196.0, 1356.0, 785.0, 0.5625035166740417]]\n",
      "Detections: [[1183.0, 211.0, 1410.0, 816.0, 0.6162042617797852]]\n",
      "Detections: [[1195.0, 219.0, 1439.0, 836.0, 0.5841314792633057]]\n",
      "Detections: [[1232.0, 265.0, 1491.0, 863.0, 0.5646979212760925]]\n",
      "Detections: [[1239.0, 261.0, 1491.0, 880.0, 0.6469612717628479]]\n",
      "Detections: [[1242.0, 257.0, 1502.0, 906.0, 0.7717761397361755]]\n",
      "Detections: [[1239.0, 269.0, 1501.0, 916.0, 0.7831037640571594]]\n",
      "Detections: [[1239.0, 269.0, 1485.0, 918.0, 0.720820963382721]]\n",
      "Detections: [[1218.0, 282.0, 1445.0, 928.0, 0.6920163035392761]]\n",
      "Detections: [[1137.0, 298.0, 1450.0, 916.0, 0.7787498235702515]]\n",
      "Detections: [[1133.0, 286.0, 1408.0, 922.0, 0.8115378022193909]]\n",
      "Detections: [[1085.0, 277.0, 1308.0, 915.0, 0.6641321778297424]]\n",
      "Detections: [[1000.0, 276.0, 1216.0, 923.0, 0.7208408117294312]]\n",
      "Detections: [[926.0, 292.0, 1220.0, 935.0, 0.8377988338470459]]\n",
      "Detections: [[903.0, 300.0, 1143.0, 922.0, 0.7347368001937866]]\n",
      "Detections: [[824.0, 291.0, 1051.0, 922.0, 0.6075028777122498]]\n",
      "Detections: [[824.0, 291.0, 1051.0, 922.0, 0.6075028777122498], [854.0, 309.0, 1039.0, 770.0, 0.5033925771713257]]\n",
      "Detections: [[752.0, 299.0, 1005.0, 917.0, 0.7942769527435303]]\n"
     ]
    }
   ],
   "source": [
    "# 3. 프레임별 처리\n",
    "tracker = DeepSort(max_age=30, nn_budget=70)  # DeepSORT 초기화\n",
    "\n",
    "object_tracks = {}  # 객체 위치 저장용 딕셔너리\n",
    "TARGET_CLASS = 1\n",
    "count_num = 0\n",
    "\n",
    "frame_count = 0\n",
    "skip_frames = 5  # 5프레임마다 한 번씩 처리\n",
    "\n",
    "print(\"영상시작\")\n",
    "\n",
    "# 첫 번째 프레임에서 프레임 크기 초기화\n",
    "ret, frame = cap.read()\n",
    "if not ret:  # 첫 번째 프레임 읽기 실패 시 프로그램 종료\n",
    "    print(\"비디오 파일을 읽을 수 없습니다.\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "frame_height, frame_width = frame.shape[:2]\n",
    "mid_x = frame_width // 2  # 화면 중간 x좌표 계산\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % skip_frames != 0:  # 프레임 스킵\n",
    "        continue\n",
    "    \n",
    "    # OpenCV BGR -> RGB 변환\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    input_tensor = tf.convert_to_tensor(rgb_frame)\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    # 객체 탐지 실행\n",
    "    detections = model(input_tensor)\n",
    "    detection_boxes = detections['detection_boxes'][0].numpy()\n",
    "    detection_classes = detections['detection_classes'][0].numpy()\n",
    "    detection_scores = detections['detection_scores'][0].numpy()\n",
    "\n",
    "    # 현재 프레임에서 탐지된 객체 정보 저장\n",
    "    current_frame_tracks = {}\n",
    "\n",
    "    # 탐지 결과 표시\n",
    "    dets = []\n",
    "\n",
    "    for i in range(len(detection_scores)):\n",
    "        if detection_scores[i] > 0.5 and detection_classes[i] == TARGET_CLASS:  # 객체 분류에 대한 신뢰도 임계값 0.5 이상으로 설정\n",
    "\n",
    "            box = detection_boxes[i] * [frame.shape[0], frame.shape[1], frame.shape[0], frame.shape[1]]\n",
    "            ymin, xmin, ymax, xmax = box.astype('int')\n",
    "            dets.append([float(xmin), float(ymin), float(xmax), float(ymax), float(detection_scores[i])])  # 형식 변환\n",
    "\n",
    "            # DeepSORT 추적 실행\n",
    "            if dets:  # dets가 비어 있지 않은 경우에만 호출\n",
    "                print(\"Detections:\", dets)  # 디버깅 출력\n",
    "                \n",
    "                # dets 데이터를 올바른 형식으로 변환\n",
    "                formatted_dets = [[d[:4], d[4]] for d in dets]  # 2D좌표(Bbox), score\n",
    "                tracks = tracker.update_tracks(formatted_dets, frame=frame)\n",
    "\n",
    "            # 추적 결과 처리\n",
    "            for track in tracks:\n",
    "                if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                    continue\n",
    "\n",
    "                track_id = track.track_id  # 객체 ID\n",
    "                l, t, r, b = track.to_ltrb()  # 추적된 경계 상자 좌표\n",
    "                center_x = int((l + r) / 2)\n",
    "\n",
    "                # 왼쪽 -> 오른쪽으로 이동\n",
    "                if center_x < mid_x and center_x >= mid_x:\n",
    "                    count_num += 1\n",
    "                    print(f\"객체 {track_id}가 왼쪽에서 오른쪽으로 이동. 현재 인원수: {count_num}\")\n",
    "\n",
    "                # 오른쪽 -> 왼쪽으로 이동\n",
    "                elif center_x > mid_x and center_x <= mid_x:\n",
    "                    count_num -= 1\n",
    "                    print(f\"객체 {track_id}가 오른쪽에서 왼쪽으로 이동. 현재 인원수: {count_num}\")\n",
    "\n",
    "                # 경계 상자 및 ID 시각화\n",
    "                cv2.rectangle(frame, (int(l), int(t)), (int(r), int(b)), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f'ID: {track_id}', (int(l), int(t) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "    \n",
    "    \n",
    "    # 영상 중간 부분에 세로선 그리기\n",
    "    cv2.line(frame, (mid_x, 0), (mid_x, frame_height), (255, 0, 0), 2)  # (255, 0, 0)은 파란색, 두께는 2\n",
    "\n",
    "    # 프레임 보여주기\n",
    "    cv2.imshow('Detection with Direction', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
