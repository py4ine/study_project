{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "model = tf.saved_model.load('./COCO-SSD_Mobilenet_V2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 로컬 영상 파일 열기\n",
    "video_path = './video/1-1_608-C05.mp4'\n",
    "cap = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영상시작\n",
      "Detections: [[593.0, 256.0, 772.0, 690.0, 0.577471137046814]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 105\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dets:  \u001b[38;5;66;03m# dets가 비어 있지 않은 경우에만 호출\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetections:\u001b[39m\u001b[38;5;124m\"\u001b[39m, dets)  \u001b[38;5;66;03m# 디버깅 출력\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     tracks \u001b[38;5;241m=\u001b[39m \u001b[43mtracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_tracks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# 추적 결과 처리\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m track \u001b[38;5;129;01min\u001b[39;00m tracks:\n",
      "File \u001b[1;32mc:\\miniconda3\\envs\\p2\\lib\\site-packages\\deep_sort_realtime\\deepsort_tracker.py:195\u001b[0m, in \u001b[0;36mDeepSort.update_tracks\u001b[1;34m(self, raw_detections, embeds, frame, today, others, instance_masks)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(raw_detections) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m: \n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolygon:\n\u001b[1;32m--> 195\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_detections\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m4\u001b[39m\n\u001b[0;32m    196\u001b[0m         raw_detections \u001b[38;5;241m=\u001b[39m [d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m raw_detections \u001b[38;5;28;01mif\u001b[39;00m d[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m d[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "# 3. 프레임별 처리\n",
    "tracker = DeepSort(max_age=30, nn_budget=70)  # DeepSORT 초기화\n",
    "\n",
    "object_tracks = {}  # 객체 위치 저장용 딕셔너리\n",
    "TARGET_CLASS = 1\n",
    "count_num = 0\n",
    "\n",
    "frame_count = 0\n",
    "skip_frames = 5  # 5프레임마다 한 번씩 처리\n",
    "\n",
    "print(\"영상시작\")\n",
    "\n",
    "# 첫 번째 프레임에서 프레임 크기 초기화\n",
    "ret, frame = cap.read()\n",
    "if not ret:  # 첫 번째 프레임 읽기 실패 시 프로그램 종료\n",
    "    print(\"비디오 파일을 읽을 수 없습니다.\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "frame_height, frame_width = frame.shape[:2]\n",
    "mid_x = frame_width // 2  # 화면 중간 x좌표 계산\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % skip_frames != 0:  # 프레임 스킵\n",
    "        continue\n",
    "    \n",
    "    # OpenCV BGR -> RGB 변환\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    input_tensor = tf.convert_to_tensor(rgb_frame)\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    # 객체 탐지 실행\n",
    "    detections = model(input_tensor)\n",
    "    detection_boxes = detections['detection_boxes'][0].numpy()\n",
    "    detection_classes = detections['detection_classes'][0].numpy()\n",
    "    detection_scores = detections['detection_scores'][0].numpy()\n",
    "\n",
    "    # 현재 프레임에서 탐지된 객체 정보 저장\n",
    "    current_frame_tracks = {}\n",
    "\n",
    "    # 탐지 결과 표시\n",
    "    dets = []\n",
    "\n",
    "    for i in range(len(detection_scores)):\n",
    "        if detection_scores[i] > 0.5 and detection_classes[i] == TARGET_CLASS:  # 객체 분류에 대한 신뢰도 임계값 0.5 이상으로 설정\n",
    "\n",
    "            # 경계 상자(지된 객체의 위치를 지정하는 사각형 영역) 좌표(실제 크기) 계산\n",
    "            # box = detection_boxes[i] * [frame.shape[0], frame.shape[1], frame.shape[0], frame.shape[1]]\n",
    "            # (ymin, xmin, ymax, xmax) = box.astype('int')\n",
    "\n",
    "            # 객체의 중심점 계산\n",
    "            # center_x = int((xmin + xmax) / 2)\n",
    "            # center_y = int((ymin + ymax) / 2)\n",
    "\n",
    "            # 임시로 객체 ID를 인덱스 `i`로 사용 (더 나은 추적 알고리즘 필요 -> 차후 deep_sort로\n",
    "            # object_id = i\n",
    "            # current_frame_tracks[object_id] = (center_x, center_y)\n",
    "\n",
    "            # # 이전 위치와 비교하여 이동 백터 계산\n",
    "            # if object_id in object_tracks:\n",
    "            #     prev_center = object_tracks[object_id]\n",
    "            #     prev_center_x, prev_center_y = object_tracks[object_id]\n",
    "            #     current_center = (center_x, center_y)\n",
    "            #     direction = (current_center[0] - prev_center[0], current_center[1] - prev_center[1])\n",
    "\n",
    "                # # 이동 거리가 너무 크면 노이즈로 간주\n",
    "                # if abs(center_x - prev_center_x) > frame_width * 0.8:\n",
    "                #     continue\n",
    "\n",
    "                # # 왼쪽 -> 오른쪽으로 이동\n",
    "                # if prev_center_x < mid_x and center_x >= mid_x:\n",
    "                #     count_num += 1\n",
    "                #     print(f\"객체 {object_id}가 왼쪽에서 오른쪽으로 이동. 현재 인원수: {count_num}\")\n",
    "                \n",
    "                # # 오른쪽 -> 왼쪽으로 이동\n",
    "                # elif prev_center_x > mid_x and center_x <= mid_x:\n",
    "                #     count_num -= 1\n",
    "                #     print(f\"객체 {object_id}가 오른쪽에서 왼쪽으로 이동. 현재 인원수: {count_num}\")\n",
    "\n",
    "                # 이동 방향 화살표\n",
    "                # cv2.arrowedLine(frame, prev_center, current_center, (0, 0, 255), 2, tipLength=0.3)\n",
    "\n",
    "            # # 현재 위치를 이전 위치로 업데이트\n",
    "            # object_tracks[object_id] = (center_x, center_y)\n",
    "\n",
    "        # # 경계 상자 및 중심점 시각화\n",
    "        # cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "        # cv2.circle(frame, (center_x, center_y), 5, (255, 0, 0), -1)\n",
    "    \n",
    "    # # 객체 이동 방향 업데이트\n",
    "    # object_tracks = current_frame_tracks\n",
    "\n",
    "            box = detection_boxes[i] * [frame.shape[0], frame.shape[1], frame.shape[0], frame.shape[1]]\n",
    "            ymin, xmin, ymax, xmax = box.astype('int')\n",
    "            dets.append([float(xmin), float(ymin), float(xmax), float(ymax), float(detection_scores[i])])  # 형식 변환\n",
    "\n",
    "            # DeepSORT 추적 실행\n",
    "            if dets:  # dets가 비어 있지 않은 경우에만 호출\n",
    "                print(\"Detections:\", dets)  # 디버깅 출력\n",
    "                tracks = tracker.update_tracks(dets, frame=frame)\n",
    "\n",
    "            # 추적 결과 처리\n",
    "            for track in tracks:\n",
    "                if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                    continue\n",
    "\n",
    "                track_id = track.track_id  # 객체 ID\n",
    "                l, t, r, b = track.to_ltrb()  # 추적된 경계 상자 좌표\n",
    "                center_x = int((l + r) / 2)\n",
    "\n",
    "                # 왼쪽 -> 오른쪽으로 이동\n",
    "                if center_x < mid_x and center_x >= mid_x:\n",
    "                    count_num += 1\n",
    "                    print(f\"객체 {track_id}가 왼쪽에서 오른쪽으로 이동. 현재 인원수: {count_num}\")\n",
    "\n",
    "                # 오른쪽 -> 왼쪽으로 이동\n",
    "                elif center_x > mid_x and center_x <= mid_x:\n",
    "                    count_num -= 1\n",
    "                    print(f\"객체 {track_id}가 오른쪽에서 왼쪽으로 이동. 현재 인원수: {count_num}\")\n",
    "\n",
    "                # 경계 상자 및 ID 시각화\n",
    "                cv2.rectangle(frame, (int(l), int(t)), (int(r), int(b)), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f'ID: {track_id}', (int(l), int(t) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "    \n",
    "    \n",
    "    # 영상 중간 부분에 세로선 그리기\n",
    "    cv2.line(frame, (mid_x, 0), (mid_x, frame_height), (255, 0, 0), 2)  # (255, 0, 0)은 파란색, 두께는 2\n",
    "\n",
    "    # 프레임 보여주기\n",
    "    cv2.imshow('Detection with Direction', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
